# ğŸ› ï¸ Autonomous System Diagnostics with Auto-Healing & Human-in-the-Loop (HITL)

A production-inspired demo showcasing **governed autonomy** in system operations â€” where **safe issues heal themselves**, and **risky actions require human approval**.

This project demonstrates how **machine learning + policy + human judgment** can work together to build **trustworthy self-healing systems**.

---

## ğŸš€ What This Project Does

This system continuously evaluates **system health signals** such as:

- Disk usage
- Memory usage
- CPU utilization
- DNS latency
- Firewall change requests

Using a trained ML model, it classifies the **operational risk level** and decides one of three outcomes:

| Decision | Meaning |
|--------|--------|
| âœ… **NO_ACTION** | System is healthy |
| âš¡ **AUTO_HEAL** | Safe remediation executed automatically |
| âœ‹ **HITL_REQUIRED** | Risky action requires human approval |

The result is a **clear, explainable, and auditable remediation workflow**.

---

## ğŸ¯ Why This Problem?

Many â€œself-healingâ€ systems fail because they:
- Automate **everything** (high risk)
- Or rely entirely on humans (slow, unscalable)

This project demonstrates a **balanced approach**:

> **Autonomy where safe.  
> Human control where risky.**

This mirrors real-world operational decision-making in:
- Infrastructure platforms
- SRE / DevOps systems
- Security operations
- AI governance systems

---

## ğŸ§  Core Design Principles

- **ML for risk classification**, not blind automation
- **Deterministic decisions** (no randomness in outcomes)
- **Human-in-the-Loop for high-blast-radius actions**
- **Clear separation of concerns**
- **Auditability by design**

---

## ğŸ§© High-Level Workflow
## ğŸ” System Workflow

```mermaid
flowchart TD
    A[System Metrics<br/>(Synthetic / Live)] --> B[Feature Builder]
    B --> C[ML Severity Classifier]
    C --> D[Decision Engine]

    D -->|AUTO_HEAL<br/>(Safe)| E[Auto Remediation]
    D -->|HITL_REQUIRED<br/>(Risky)| F[Human Approval UI]

    E --> G[Action Taken]
    F --> H[Approve / Reject]

    G --> I[Audit Log<br/>(Governance)]
    H --> I
```



## ğŸ¤– The ML Model (Simple, Explainable, Purposeful)

### Model Objective
Classify **operational severity**, not predict complex time-series.

### Input Features
- `disk_usage (%)`
- `memory_usage (%)`
- `cpu_usage (%)`
- `dns_latency (ms)`
- `firewall_change_requested (0/1)`

### Output Classes
| Class | Meaning |
|-----|--------|
| `0` | NO_ACTION |
| `1` | AUTO_HEAL |
| `2` | HITL_REQUIRED |

The model is trained **locally** using MLflow and exported as an approved artifact.

---

## ğŸ” Auto-Healing vs HITL (By Design)

### âœ… Auto-Healing (Safe)
Actions that are:
- Reversible
- Low blast radius
- Operationally safe

Examples:
- Disk cleanup
- Memory cleanup
- Restarting a high-CPU service

### âœ‹ Human-in-the-Loop (Risky)
Actions that are:
- Security-sensitive
- Network-impacting
- Potentially disruptive

Examples:
- DNS configuration changes
- Firewall port modifications

This distinction is intentional and realistic.

---

## ğŸ§‘â€âš–ï¸ Human-in-the-Loop Experience

When HITL is required, the UI shows:
- Current system metrics
- Proposed actions
- Approval / rejection controls
- Notes for context

Every human decision is **logged for auditability**.

---

## ğŸ“Š Streamlit UI Features

- ğŸ”„ **Refresh button** to pull live metrics
- ğŸ“Š Live system diagnostics
- ğŸ§­ Clear decision banner
- âš¡ Auto-healing status
- âœ‹ HITL approval workflow
- ğŸ§¾ Audit trail (JSON-based)

Designed to feel like a **real operations console**, not a toy demo.


## ğŸ§ª How to Run Locally

### 1ï¸âƒ£ Train the model (once)
```bash
python -m model.train_severity_model

```
## Run the UI

```bash
streamlit run app.py
```




